id: crime_schedule
namespace: phillycrime
description: |
  Flow to grab philadelphia crime data from open data philly website every day. 

inputs:
    # Input to specify the year
  - id: year
    type: SELECT
    displayName: Select year
    values: ['2006', '2007', '2008', '2009' , '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025']
    defaults: "2025"
  
variables:
  base_url_post: 'https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%27'  
  base_url_pre: 'https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%27'
  mid_url: '-01-01%27%20AND%20dispatch_date_time%20%3C%20%27'
  end_url: '-01-01%27'
  full_url_post: "{{vars.base_url_post}}{{inputs.year}}{{vars.mid_url}}{{inputs.year | number + 1}}{{vars.end_url}}"
  full_url_pre: "{{vars.base_url_pre}}{{inputs.year}}{{vars.mid_url}}{{inputs.year | number + 1}}{{vars.end_url}}"
  output_name: "crime_{{inputs.year}}.csv"
  gcs_file: "gs://{{kv('GCP_BUCKET_NAME')}}/{{vars.output_name}}"
  table: "{{kv('GCP_DATASET')}}.Crime_{{inputs.year}}"
  data_post: "{{outputs.extractpost.outputFiles['crime_'~inputs.year~'.csv']}}"
  data_pre: "{{outputs.extractpre.outputFiles['crime_'~inputs.year~'.csv']}}"

tasks:
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: "{{render(vars.full_url_post)}}"

    # Check if >= 2020
  - id: if_post_2020
    type: io.kestra.plugin.core.flow.If
    condition: "{{inputs.year | number >= 2020}}"
    then:
    # Task to download the crime csv file 
    - id: extractpost
      type: io.kestra.plugin.scripts.shell.Commands
      outputFiles:
        - "*.csv"
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      commands:
        - curl -o {{render(vars.output_name)}} -L '{{render(vars.full_url_post)}}'

    - id: transform_data_post
      type: io.kestra.plugin.scripts.python.Script
      outputFiles:
        - '{{render(vars.output_name)}}'
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      warningOnStdErr: false
      beforeCommands:
      - pip install pandas
      script: | 
        import pandas as pd
        
        # Load csv
        df = pd.read_csv("{{render(vars.data_post)}}")
        
        # Clean a little
        keep_cols = ['objectid', 'dc_dist', 'dispatch_date', 'hour', 'location_block', 'text_general_code', 'lat', 'lng']
        df = df[keep_cols]
        df = df.dropna(subset=['lat', 'lng', 'hour', 'location_block'])
        df['dispatch_date'] = pd.to_datetime(df['dispatch_date'])
        df['hour'] = df['hour'].astype(int)
        
        df.to_csv('{{render(vars.output_name)}}', index=False)

    - id: upload_gcs_post
      type: io.kestra.plugin.gcp.gcs.Upload
      from: "{{outputs.transform_data_post.outputFiles[render(vars.output_name)]}}"
      to: "{{render(vars.gcs_file)}}"


  - id: if_pre_2020
    type: io.kestra.plugin.core.flow.If
    condition: "{{inputs.year | number < 2020}}"
    then:
    # Task to download the crime csv file 
    - id: extractpre
      type: io.kestra.plugin.scripts.shell.Commands
      outputFiles:
        - "*.csv"
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      commands:
        - curl -o {{render(vars.output_name)}} -L '{{render(vars.full_url_pre)}}' 

    - id: transform_data_pre
      type: io.kestra.plugin.scripts.python.Script
      outputFiles:
        - '{{render(vars.output_name)}}'
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      warningOnStdErr: false
      beforeCommands:
      - pip install pandas
      script: | 
        import pandas as pd
        
        # Load csv
        df = pd.read_csv("{{render(vars.data_pre)}}")
        
        # Clean a little
        keep_cols = ['objectid', 'dc_dist', 'dispatch_date', 'hour', 'location_block', 'text_general_code', 'lat', 'lng']
        df = df[keep_cols]
        df = df.dropna(subset=['lat', 'lng', 'hour', 'location_block'])
        df['dispatch_date'] = pd.to_datetime(df['dispatch_date'])
        df['hour'] = df['hour'].astype(int)
        
        df.to_csv('{{render(vars.output_name)}}', index=False)

    - id: upload_gcs_pre
      type: io.kestra.plugin.gcp.gcs.Upload
      from: "{{outputs.transform_data_pre.outputFiles[render(vars.output_name)]}}"
      to: "{{render(vars.gcs_file)}}"           

   # Create the BQ table that will hold final data
  - id: bq_crimedata
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
          CREATE TABLE IF NOT EXISTS `{{kv('GCP_PROJECT_ID')}}.{{kv('GCP_DATASET')}}.phillycrimes
          (
            unique_row_id BYTES OPTIONS(description='A unique identifier for the trip, generated by hashing key trip attributes.')
            ,filename STRING OPTIONS(description='Source filename')
            ,objectid INTEGER OPTIONS(description='Unique identifier for row from the source')
            ,dc_dist INTEGER OPTIONS(description='Integer representing the police district where the crime happened')
            ,dispatch_date TIMESTAMP OPTIONS(description='Date the crime happened')
            ,hour INTEGER OPTIONS(description='Hour the crime happened')
            ,location_block STRING OPTIONS(description='String representing the block the crime happened on')
            ,text_general_code STRING OPTIONS(description='String representing category of crime committed')
            ,lat NUMERIC OPTIONS(description='Represents the latitude coordinate of crime')
            ,lng NUMERIC OPTIONS(description='Represents the longitude coordinate of crime ')
          )
          PARTITION BY DATE(dispatch_date);

  - id: bq_crimedata_ext
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
          CREATE OR REPLACE EXTERNAL TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}_ext`
          (
            objectid INTEGER OPTIONS(description='Unique identifier for row from the source')
            ,dc_dist INTEGER OPTIONS(description='Integer representing the police district where the crime happened')
            ,dispatch_date TIMESTAMP OPTIONS(description='Date the crime happened')
            ,hour INTEGER OPTIONS(description='Hour the crime happened')
            ,location_block STRING OPTIONS(description='String representing the block the crime happened on')
            ,text_general_code STRING OPTIONS(description='String representing category of crime committed')
            ,lat NUMERIC OPTIONS(description='Represents the latitude coordinate of crime')
            ,lng NUMERIC OPTIONS(description='Represents the longitude coordinate of crime ')
          )
          PARTITION BY DATE(dispatch_date);          

# bq external table, bq temp table, merge temp into final 

  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{kv('GCP_CREDS')}}"
      projectId: "{{kv('GCP_PROJECT_ID')}}"
      location: "{{kv('GCP_LOCATION')}}"
      bucket: "{{kv('GCP_BUCKET_NAME')}}"

